{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L3tUO7Bi4Tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.utils import compute_ap\n",
        "from mrcnn.model import load_image_gt\n",
        "from mrcnn.model import mold_image\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h5tA0ujjAU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_ANNOT = \"/content/drive/My Drive/LicensePlateProject/license_plates_detection_train/annots\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIo9rfuqjFkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class licensePateDataset(Dataset):\n",
        "\t# load the dataset definitions\n",
        "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
        "\t\t# define one class\n",
        "\t\tself.add_class(\"dataset\", 1, \"licencePlate\")\n",
        "\t\t# define data locations\n",
        "\t\timages_dir = dataset_dir + '/images/'\n",
        "\t\tannotations_dir = dataset_dir + '/annots/'\n",
        "\t\t# find all images\n",
        "\t\tfor filename in listdir(images_dir):\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename[:-4]\n",
        "\t\t\t# skip all images after 800 if we are building the train set\n",
        "\t\t\tif is_train and int(image_id) >= 800:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images before 800 if we are building the validation set\n",
        "\t\t\tif not is_train and int(image_id) < 800:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        " \n",
        "\t# extract bounding boxes from an annotation file\n",
        "\tdef extract_boxes(self, filename):\n",
        "         tree = ElementTree.parse(filename)\n",
        "        # get the root of the document\n",
        "         root = tree.getroot()\n",
        "        # extract each bounding box\n",
        "         boxes = list()\n",
        "         for box in root.findall('.//bndbox'):\n",
        "             xmin = int(box.find('xmin').text)\n",
        "             ymin = int(box.find('ymin').text)\n",
        "             xmax = int(box.find('xmax').text)\n",
        "             ymax = int(box.find('ymax').text)\n",
        "             coors = [xmin, ymin, xmax, ymax]\n",
        "             boxes.append(coors)\n",
        "        # extract image dimensions\n",
        "         width = int(root.find('.//size/width').text)\n",
        "         height = int(root.find('.//size/height').text)\n",
        "         return boxes, width, height\n",
        " \n",
        "\t# load the masks for an image\n",
        "\tdef load_mask(self, image_id):\n",
        "\t\t# get details of image\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\t# define box file location\n",
        "\t\tpath = info['annotation']\n",
        "\t\t# load XML\n",
        "\t\tboxes, w, h = self.extract_boxes(path)\n",
        "\t\t# create one array for all masks, each on a different channel\n",
        "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# create masks\n",
        "\t\tclass_ids = list()\n",
        "\t\tfor i in range(len(boxes)):\n",
        "\t\t\tbox = boxes[i]\n",
        "\t\t\trow_s, row_e = box[1], box[3]\n",
        "\t\t\tcol_s, col_e = box[0], box[2]\n",
        "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
        "\t\t\tclass_ids.append(self.class_names.index('licencePlate'))\n",
        "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
        " \n",
        "\t# load an image reference\n",
        "\tdef image_reference(self, image_id):\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\treturn info['path']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubTAD8OJnNaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a configuration for the model\n",
        "class LicensePlateConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"LicensePlate_cfg\"\n",
        "\t# number of classes (background + kangaroo)\n",
        "\tNUM_CLASSES = 1 + 1\n",
        "\t# number of training steps per epoch\n",
        "\tSTEPS_PER_EPOCH = 131\n",
        "\t# simplify GPU config\n",
        "\tGPU_COUNT = 1\n",
        "\tIMAGES_PER_GPU = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSwB9cbOI9aZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the mAP for a model on a given dataset\n",
        "def evaluate_model(dataset, model, cfg):\n",
        "\tAPs = list()\n",
        "\tfor image_id in dataset.image_ids:\n",
        "\t\t# load image, bounding boxes and masks for the image id\n",
        "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t# extract results for first sample\n",
        "\t\tr = yhat[0]\n",
        "\t\t# calculate statistics, including AP\n",
        "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\t\t# store\n",
        "\t\tAPs.append(AP)\n",
        "\t# calculate the mean AP across all images\n",
        "\tmAP = mean(APs)\n",
        "\treturn mAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz7w5EQljQPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train set\n",
        "train_set = licensePateDataset()\n",
        "train_set.load_dataset('/content/drive/My Drive/LicensePlateProject/license_plates_detection_train', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        " \n",
        "# test/val set\n",
        "test_set = licensePateDataset()\n",
        "test_set.load_dataset('/content/drive/My Drive/LicensePlateProject/license_plates_detection_train', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_AnDCOQnT2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare config\n",
        "config = LicensePlateConfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTWpoznancZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the model\n",
        "model = MaskRCNN(mode='inference', model_dir='./', config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JAa1u28njwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load weights (mscoco) and exclude the output layers\n",
        "model.load_weights('/content/licenseplate_cfg20200508T1727/mask_rcnn_licenseplate_cfg_0010.h5', by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yUPrIMRJMks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6fd06f98-9499-4b89-bd9c-64b69768a362"
      },
      "source": [
        "# evaluate model on training dataset \n",
        "# Uncomment if you want to evaluate the train\n",
        "#train_mAP = evaluate_model(train_set, model, config)\n",
        "#print(\"Train mAP: %.3f\" % train_mAP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3mgIu_7Ow70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8bca98f-55e9-420f-975d-dac0f1792a52"
      },
      "source": [
        "# evaluate model on test dataset\n",
        "# Uncomment if you want to evaluate the test\n",
        "#test_mAP = evaluate_model(test_set, model, config)\n",
        "#print(\"Test mAP: %.3f\" % test_mAP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuzBcJn_R5sK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot a number of photos with ground truth and predictions\n",
        "def plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n",
        "\t# load image and mask\n",
        "\tfor i in range(n_images):\n",
        "\t\t# load the image and mask\n",
        "\t\timage = dataset.load_image(i)\n",
        "\t\tmask, _ = dataset.load_mask(i)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)[0]\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(n_images, 2, i*2+1)\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(image)\n",
        "\t\tpyplot.title('Actual')\n",
        "\t\t# plot masks\n",
        "\t\tfor j in range(mask.shape[2]):\n",
        "\t\t\tpyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "\t\t# get the context for drawing boxes\n",
        "\t\tpyplot.subplot(n_images, 2, i*2+2)\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(image)\n",
        "\t\tpyplot.title('Predicted')\n",
        "\t\tax = pyplot.gca()\n",
        "\t\t# plot each box\n",
        "\t\tfor box in yhat['rois']:\n",
        "\t\t\t# get coordinates\n",
        "\t\t\ty1, x1, y2, x2 = box\n",
        "\t\t\t# calculate width and height of the box\n",
        "\t\t\twidth, height = x2 - x1, y2 - y1\n",
        "\t\t\t# create the shape\n",
        "\t\t\trect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "\t\t\t# draw the box\n",
        "\t\t\tax.add_patch(rect)\n",
        "\t# show the figure\n",
        "\tpyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3v4Y4d2SNFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot predictions for train dataset\n",
        "plot_actual_vs_predicted(train_set, model, config)\n",
        "# plot predictions for test dataset\n",
        "plot_actual_vs_predicted(test_set, model, config)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Training_v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python38264bitlicenceplaterecconda929b75812cc84b58b1c904b5826288a5",
      "display_name": "Python 3.8.2 64-bit ('licencePlateRec': conda)"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}